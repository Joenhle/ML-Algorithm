#### 5.1

A，C

#### 5.2

A

#### 5.3

B,D

#### 5.4

A

#### 5.5

B

#### 5.6

B

#### 5.7

A

支持向量机

学习策略:通过找到一个最大间隔超平面来划分数据集

算法:先构造原问题的对偶问题，然后利用二次规划求解器求解$\alpha^*$,于是就能计算出$w^*,b^*$

逻辑回归模型

学习策略:通过找到一组最优$w^*$，然后通过sigmod函数求得该模型下某一类预测结果的后验概率

算法:通过梯度下降法求得目标函数J(w)的最小时的参数$w^*$

AdaBoost

学习策略:在分类或回归问题中，通过改变训练样本的权重，学习多个base模型，并将这些模型进行线性组合，提高分类的性能。

算法:

(1)初始化训练数据的权值分布

(2)对m=1,2,...M

​	(a)使用具有权值分布的训练数据集学习，得到基本分类器

​	(b)计算在训练数据集上的分类误差

​	(c)计算$G_m(x)$的系数

​	(d)更新训练数据集的权值分布

(3)构建基本分类器的线性组合得到最终分类器